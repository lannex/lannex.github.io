{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/blog/2020/EFK-Fluentd-Fluentbit/","result":{"data":{"site":{"siteMetadata":{"title":"lannex"}},"markdownRemark":{"id":"f1ba0896-3fd1-5a8c-8adf-67b702f0512d","excerpt":"현재 사내에서는 컨테이너 오케스트레이션 툴로 Docker Swarm을 사용하고 있습니다. Kubernetes 전환 얘기가 솔솔 나오는 와중에 새로운 프로덕트를 내놓게 되었는데 이 과정에서 EFK를 사용하여 Logging을 구축한 경험, 특히 Fluent Bit과 Fluentd…","html":"<p>현재 사내에서는 컨테이너 오케스트레이션 툴로 Docker Swarm을 사용하고 있습니다. Kubernetes 전환 얘기가 솔솔 나오는 와중에 새로운 프로덕트를 내놓게 되었는데 이 과정에서 EFK를 사용하여 Logging을 구축한 경험, 특히 Fluent Bit과 Fluentd를 중심으로 기본 설정에 관해 이야기해볼까 합니다.</p>\n<h1>👀 ELK와 EFK Stack?</h1>\n<p>EFK란 Elasticsearch, Fluentd 그리고 Kibana의 첫 글자를 딴 약자입니다. 대표적으로 알려진 ELK는 Elasticsearch, Logstash 와 Kibana의 약자이며 두 Stack의 차이로는 로그 수집기를 Fluentd로 사용할 것인지 아니면 Logstash로 사용할 것인지 말고는 없습니다.</p>\n<p>한 단계 더 가서 Logstash와 Fluentd의 차이점을 얘기해보자면 Logstash는 자바 런타임이 필요한 JRuby로 되어있으며 Fluentd는 자바 런타임이 필요하지 않은 CRuby로 되어있습니다. 그리고 Logstash에 비해 Fluentd는 조금 더 가벼우며 때에 따라 로그 전송만 담당하는, 더욱 경량화된 Fluent Bit을 사용 할 수 있습니다.</p>\n<h1>📐 Architecture</h1>\n<p>기본적인 구조는 아래와 같습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d14a60a80d68a075a37921dbb069e115/eea4a/efk.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.49999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHutEil/8QAGBAAAgMAAAAAAAAAAAAAAAAAABEBICH/2gAIAQEAAQUCesin/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhAAAwAAAAAAAAAAAAAAAAAAACAx/9oACAEBAAY/AiL/AP/EABoQAAMBAAMAAAAAAAAAAAAAAAERIQAgMWH/2gAIAQEAAT8hZo7mtd4iQyF5w//aAAwDAQACAAMAAAAQf8//xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAwEBPxCH/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQIBAT8QZ//EABkQAQEBAQEBAAAAAAAAAAAAAAERACFBUf/aAAgBAQABPxAg8CeeEuQFeQFOn3A0t9eaHeaYJv/Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"EFK\"\n        title=\"EFK\"\n        src=\"/static/d14a60a80d68a075a37921dbb069e115/4b190/efk.jpg\"\n        srcset=\"/static/d14a60a80d68a075a37921dbb069e115/e07e9/efk.jpg 200w,\n/static/d14a60a80d68a075a37921dbb069e115/066f9/efk.jpg 400w,\n/static/d14a60a80d68a075a37921dbb069e115/4b190/efk.jpg 800w,\n/static/d14a60a80d68a075a37921dbb069e115/e5166/efk.jpg 1200w,\n/static/d14a60a80d68a075a37921dbb069e115/eea4a/efk.jpg 1280w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>각 클라이언트에서 내부 네트워크로 구성된 서버에 Fluent Bit으로 log를 수집 후 외부 네트워크가 가능한 서버로 전송합니다. 데이터를 받는 서버에서는 Fluentd를 Aggregator의 역할로 구성하고 다시 Elasticsearch로 데이터를 전송, Kibana는 Elasticsearch의 데이터를 시각화합니다.</p>\n<h1>🤲 Fluent Bit과 Fluentd</h1>\n<p>앞서 언급했듯이 Fluent Bit은 Fluentd의 경량화된 버전으로 C로 만들어졌습니다. 서버 환경이 워낙 좋아져서 크게 상관은 없지만 서버에서 Forwarder만 담당한다면 좀 더 가벼운 Fluent Bit을 사용하는 것이 좋습니다.</p>\n<h1>👉 Input → Parser → Filter → Output</h1>\n<p>Fluent Bit과 Fluentd의 파이프라인은 중간중간 추가되는 과정이 있어서 조금은 다르지만 크게는 이러한 과정으로 진행됩니다.</p>\n<ol>\n<li>Input: 서로 다른 소스에서 어떤 데이터를 수집할 지 결정</li>\n<li>Parser: 수집하는 데이터를 구조화하는 파싱</li>\n<li>Filter: 데이터를 특정 대상으로 전달하기 전에 데이터를 가공</li>\n<li>Output: 가공된 데이터를 내보내는 방식을 정의</li>\n</ol>\n<p>각 과정에서 다양한 플러그인들이 제공되며 설정을 정의함으로써 원하는 값을 도출하게끔 제어할 수 있습니다.</p>\n<h1>🚢 Forwarder (Fluent Bit)</h1>\n<p>프로덕트는 보안상의 이유로 여러 클라이언트에게 on-premise 형태로 제공하고 있습니다. 내부 네트워크로 구성된 서버에는 Docker Swarm으로 오케스트레이션 되니 먼저 많은 Docker들의 Log를 추적해야 했습니다. (Ubuntu 기준으로 Docker Log 위치는 <code class=\"language-text\">/var/lib/docker/containers/&lt;container id&gt;/&lt;container id&gt;-json.log</code>)</p>\n<p>각 클라이언트 서버에선 Forwarder로만 사용하기에 Docker Build로 Fluent Bit를 설정하여 서비스합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"properties\"><pre class=\"language-properties\"><code class=\"language-properties\"><span class=\"token comment\"># inputs.conf</span>\n\n[INPUT]\n<span class=\"token attr-name\">  Name</span> <span class=\"token attr-value\">             tail</span>\n<span class=\"token attr-name\">  Parser</span> <span class=\"token attr-value\">           docker</span>\n<span class=\"token attr-name\">  Path</span> <span class=\"token attr-value\">             /var/lib/docker/containers/*/*.log</span>\n<span class=\"token attr-name\">  Docker_Mode</span> <span class=\"token attr-value\">      On</span>\n<span class=\"token attr-name\">  Tag</span> <span class=\"token attr-value\">              docker.&lt;file_name></span>\n<span class=\"token attr-name\">  Tag_Regex</span> <span class=\"token attr-value\">        (?&lt;file_name>[a-z0-9]*)-json.log</span>\n\t...</code></pre></div>\n<p>Logging은 Docker 외에도 여러 개 Input을 작성하다 보면 설정 파일이 길어지게 됩니다. 거기에다 각종 Filter 등 다른 과정까지 포함하다 보면 하나의 설정 파일에 감당하기 어렵습니다. 그래서 각 과정을  <code class=\"language-text\">@INCLUDE</code> 를 사용하여 여러 파일로 모듈화를 하면 좋습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"properties\"><pre class=\"language-properties\"><code class=\"language-properties\"><span class=\"token comment\"># fluent-bit.conf</span>\n\n<span class=\"token attr-name\">@INCLUDE</span> <span class=\"token attr-value\">/fluent-bit/etc/inputs.conf</span>\n\n<span class=\"token attr-name\">@INCLUDE</span> <span class=\"token attr-value\">/fluent-bit/etc/filters.conf</span>\n\n...</code></pre></div>\n<p>Docker Log를 이렇게 수집한 뒤 여러 Filter를 거쳐서 데이터를 원하는 형태로 가공해야 합니다. 그런고로 Filter야말로 핵심이라 할 수 있습니다.</p>\n<p>무엇보다 Input 설정에서 Tag를 <code class=\"language-text\">container id (file_name)</code> 로 받기 때문에 각 Docker에서 나오는 Log를 인식할 수 있는 값으로 변환해야 하는 것이 중요합니다. 이를 위해 lua 스크립트를 사용해서 docker_metadata를 매칭한 뒤 태그를 변경하는 방법으로 필터링합니다.(참고 <a href=\"https://github.com/fluent/fluent-bit/issues/1499\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">lua script</a>)</p>\n<div class=\"gatsby-highlight\" data-language=\"properties\"><pre class=\"language-properties\"><code class=\"language-properties\"><span class=\"token comment\"># filters.conf</span>\n\n[FILTER]\n<span class=\"token attr-name\">  Name</span> <span class=\"token attr-value\">             lua</span>\n<span class=\"token attr-name\">  Match</span> <span class=\"token attr-value\">            docker.*</span>\n<span class=\"token attr-name\">  script</span> <span class=\"token attr-value\">           /fluent-bit/bin/docker-metadata.lua</span>\n<span class=\"token attr-name\">  call</span> <span class=\"token attr-value\">             encrich_with_docker_metadata</span>\n\n[FILTER]\n<span class=\"token attr-name\">  Name</span> <span class=\"token attr-value\">             record_modifier</span>\n<span class=\"token attr-name\">  Match</span> <span class=\"token attr-value\">            docker.*</span>\n<span class=\"token attr-name\">  Whitelist_key</span> <span class=\"token attr-value\">    log</span>\n<span class=\"token attr-name\">  Whitelist_key</span> <span class=\"token attr-value\">    docker.container_name</span>\n  ...\n\n[FILTER]\n<span class=\"token attr-name\">  Name</span> <span class=\"token attr-value\">             modify</span>\n<span class=\"token attr-name\">  Match</span> <span class=\"token attr-value\">            docker.*</span>\n<span class=\"token attr-name\">  Rename</span> <span class=\"token attr-value\">           docker.container_name container_name</span>\n\t...\n\n[FILTER]\n<span class=\"token attr-name\">  Name</span> <span class=\"token attr-value\">             rewrite_tag</span>\n<span class=\"token attr-name\">  Match</span> <span class=\"token attr-value\">            docker.*</span>\n<span class=\"token attr-name\">  Rule</span> <span class=\"token attr-value\">             $container_name (.*) docker.$0 false</span>\n\n...</code></pre></div>\n<p>또한 grep을 써서 선택적으로 데이터를 취하거나 제외할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"properties\"><pre class=\"language-properties\"><code class=\"language-properties\"><span class=\"token comment\"># filters.conf</span>\n\n[FILTER]\n<span class=\"token attr-name\">  Name</span> <span class=\"token attr-value\">             grep</span>\n<span class=\"token attr-name\">  Match</span> <span class=\"token attr-value\">            docker.*</span>\n<span class=\"token attr-name\">  Exclude</span> <span class=\"token attr-value\">          container_name (.*fluent).+</span>\n  ...</code></pre></div>\n<p>이 후 Output에 forward로 Aggregator에게 데이터를 보내면 됩니다.</p>\n<h1>🗃 Aggregator (Fluentd)</h1>\n<p>각 클라이언트에서 저마다 보내오는 데이터를 Fluentd가 수집해서 Elasticsearch로 전송합니다. 이 역할은 한 곳에서만 담당하며 Elasticsearch와 Kibana를 같은 서버에서 함께 사용해도 됩니다.</p>\n<p>Elasticsearch로 데이터를 전송하기 위해 Fluentd의 <code class=\"language-text\">fluent-plugin-elasticsearch</code>라는 플러그인의 설치가 우선되어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"docker\"><pre class=\"language-docker\"><code class=\"language-docker\"><span class=\"token comment\"># Dockerfile</span>\n\n<span class=\"token keyword\">FROM</span> fluent/fluentd<span class=\"token punctuation\">:</span>v1.11<span class=\"token punctuation\">-</span>1\n\n<span class=\"token keyword\">USER</span> root\n\n<span class=\"token keyword\">RUN</span> apk add <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>no<span class=\"token punctuation\">-</span>cache <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>update <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>virtual .build<span class=\"token punctuation\">-</span>deps \\\n  sudo build<span class=\"token punctuation\">-</span>base ruby<span class=\"token punctuation\">-</span>dev \\\n  &amp;&amp; sudo gem install \\\n    fluent<span class=\"token punctuation\">-</span>plugin<span class=\"token punctuation\">-</span>concat \\\n    fluent<span class=\"token punctuation\">-</span>plugin<span class=\"token punctuation\">-</span>elasticsearch \\\n  &amp;&amp; apk del .build<span class=\"token punctuation\">-</span>deps \\\n  &amp;&amp; rm <span class=\"token punctuation\">-</span>rf /tmp/* /var/tmp/* /usr/lib/ruby/gems/*/cache/*.gem\n\n<span class=\"token keyword\">COPY</span> conf/* /fluentd/etc/\n<span class=\"token keyword\">COPY</span> entrypoint.sh /bin/\n\n<span class=\"token keyword\">RUN</span> chmod +x /bin/entrypoint.sh\n\n<span class=\"token keyword\">USER</span> fluent</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"># fluent.conf\n\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>match</span> <span class=\"token attr-name\">docker.swarm_reception-api**</span><span class=\"token punctuation\">></span></span>\n  @type elasticsearch_dynamic\n  logstash_format true\n\tlogstash_prefix ${record['biz_client']}-reception-api\n\t...\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>match</span><span class=\"token punctuation\">></span></span>\n\n...</code></pre></div>\n<p>다양한 클라이언트에서 데이터를 전송받으니 어떤 클라이언트인지 식별할 필요가 있습니다. Forwarder가 식별할 record를 하나 지정해서 보내주면 type을 <code class=\"language-text\">elasticsearch_dynamic</code> 로 선언해서 유동적으로 처리할 수 있습니다.</p>\n<p>다중 match와 label등을 활용하여 데이터를 다시 분류 후 Elasticsearch로 전송하면 이를 바탕으로 드디어 Kibana에서 시각화가 가능해집니다.</p>\n<h1>📊 Elasticsearch와 Kibana</h1>\n<p>Elasticsearch와 Kibana는 직접 설치해서 사용해도 되지만 최근에는 여러 클라우드에서 쉽게 배포까지 자동으로 하는 환경을 만들어 줍니다. 더군다나 <a href=\"https://elastic.co\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">elastic.co</a>에서는 사이트 내에서 클라우드로 자동 배포하고 매니지먼트까지 할 수 있는 기능들을 제공합니다.</p>\n<p>배포 후 Kibana에 접속하여 Stack Management에서 Index Management를 확인해보면 index가  <code class=\"language-text\">&lt;client_name&gt;-&lt;docker_name&gt;-&lt;date&gt;</code>의 형식으로 생성되는 것을 확인할 수 있습니다.</p>\n<p>이를 토대로 Kibana 인덱스 패턴을 만들면 EFK의 기본 과정은 끝이 납니다.</p>\n<h1>📃 끝으로</h1>\n<p>큰 Pipeline은 이렇게 구성되었습니다. 실제로는 더 다양하고 많은 Filter들과 설정들로 다소 복잡하게 구성됩니다. 그래도 제대로 가공된 데이터만 Elasticsearch로 전송할 수 있다면 Kibana에서 정말 편하게 다양한 정보를 확인할 수 있습니다.</p>\n<p>그럼 여기까지 MSA, Docker Swarm Loggin을 위한 EFK 였습니다.</p>","frontmatter":{"title":"EFK Stack, 그 중에 Fluentd와 Fluent Bit","date":"December 15, 2020","description":"EFK Stack으로 Docker Swarm Logging 구축","tags":"devops"}}},"pageContext":{"slug":"/blog/2020/EFK-Fluentd-Fluentbit/","previous":{"fields":{"slug":"/blog/2020/github-action/"},"frontmatter":{"title":"Github Actions로 간단한 Azure Static Web Page 배포"}},"next":{"fields":{"slug":"/blog/2021/why-rust-is-a-modern-programming-language/"},"frontmatter":{"title":"Rust가 \"현대적인\" 프로그래밍 언어인 이유 (번역)"}}}},"staticQueryHashes":["1137390604","3980716358"]}